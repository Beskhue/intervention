#!/usr/bin/env python3
"""Intervention learning entrypoints."""

from typing import Optional

import click
from pathlib import Path
from loguru import logger
import sys


@click.group()
def cli():
    pass


@cli.command()
def demo():
    import intervention.run

    intervention.run.demo()


@cli.command()
def manual():
    import intervention.run

    intervention.run.manual()


@cli.command()
def collect():
    import intervention.run

    intervention.run.collect()


@cli.command()
@click.option(
    "-n",
    "--num_episodes",
    default=1,
    type=int,
    help="The number of episodes to collect. Terminated episodes also count.",
)
@click.option(
    "-d",
    "--directory",
    default=".",
    type=click.Path(
        exists=False, file_okay=False, dir_okay=True, writable=True, readable=True
    ),
    help=(
        "The directory to write the episodes to. This directory will contain a "
        "top-level file to which summary information is written. If the file exists, "
        "will be appended to. Per-episode data is written to their own subdirectories."
    ),
)
def collect_teacher_examples(num_episodes: int, directory: str):
    """
    Collect examples of driving from a teacher agent.
    """
    import intervention.run

    data_path = Path(directory)
    data_path.mkdir(parents=True, exist_ok=True)

    intervention.run.collect_example_episodes(
        data_path=data_path, num_episodes=num_episodes
    )


@cli.command()
@click.option(
    "device_name",
    "--device",
    default="cuda:0",
    type=str,
    help=(
        "The device to run on. "
        "See torch's documentation on torch.device for more information."
    ),
)
@click.option(
    "-o",
    "--output-directory",
    default=".",
    type=click.Path(
        exists=False, file_okay=False, dir_okay=True, writable=True, readable=True
    ),
    help=("The directory to write the output checkpoints to."),
)
@click.option(
    "-i",
    "--initial-checkpoint",
    required=False,
    type=click.Path(exists=True, file_okay=True, dir_okay=False, readable=True),
    help=("The checkpoint to resume training from."),
)
def train_test(
    device_name: str, output_directory: str, initial_checkpoint: Optional[str]
):
    import torch
    import intervention.train.train

    output_path = Path(output_directory)
    output_path.mkdir(parents=True, exist_ok=True)

    initial_checkpoint_path = Path(initial_checkpoint) if initial_checkpoint else None

    device = torch.device(device_name)
    intervention.train.train.test(
        device, output_path, initial_checkpoint_path=initial_checkpoint_path
    )


if __name__ == "__main__":
    logger.remove(handler_id=0)  # Remove default handler.
    logger.add(
        sys.stderr,
        level="TRACE",
        format=(
            "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green>"
            "| <red>{process.name: <10} {thread.name: <10}</red>"
            "| <level>{level: <8}</level>"
            "| <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan>"
            "- <level>{message}</level>"
        ),
    )

    cli()
